{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 23:13:48,540] A new study created in memory with name: no-name-39654841-83de-478c-bc25-91e01f8ffc06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeat:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 23:14:17,977] Trial 0 finished with value: 90.08620689655173 and parameters: {'n_linear_layers': 1, 'n_units_l0': 158, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.004705244629527424}. Best is trial 0 with value: 90.08620689655173.\n",
      "[I 2024-12-21 23:14:46,379] Trial 1 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 1, 'n_units_l0': 441, 'activation': 'ReLU', 'optimizer': 'Adam', 'lr': 3.1155868346230006e-05}. Best is trial 0 with value: 90.08620689655173.\n",
      "[I 2024-12-21 23:15:15,041] Trial 2 finished with value: 89.22413793103449 and parameters: {'n_linear_layers': 2, 'n_units_l0': 195, 'activation': 'Tanh', 'n_units_l1': 228, 'optimizer': 'RMSprop', 'lr': 5.669118454828521e-05}. Best is trial 0 with value: 90.08620689655173.\n",
      "[I 2024-12-21 23:15:40,067] Trial 3 finished with value: 87.93103448275862 and parameters: {'n_linear_layers': 1, 'n_units_l0': 110, 'activation': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.020215203725185715}. Best is trial 0 with value: 90.08620689655173.\n",
      "[I 2024-12-21 23:16:08,220] Trial 4 finished with value: 82.75862068965517 and parameters: {'n_linear_layers': 1, 'n_units_l0': 716, 'activation': 'ReLU', 'optimizer': 'SGD', 'lr': 0.0002476857166552171}. Best is trial 0 with value: 90.08620689655173.\n",
      "[I 2024-12-21 23:16:37,428] Trial 5 finished with value: 90.94827586206897 and parameters: {'n_linear_layers': 2, 'n_units_l0': 347, 'activation': 'ReLU', 'n_units_l1': 120, 'optimizer': 'Adam', 'lr': 0.0012373312350259724}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:16:39,025] Trial 6 pruned. \n",
      "[I 2024-12-21 23:16:40,427] Trial 7 pruned. \n",
      "[I 2024-12-21 23:16:41,917] Trial 8 pruned. \n",
      "[I 2024-12-21 23:16:43,933] Trial 9 pruned. \n",
      "[I 2024-12-21 23:16:45,371] Trial 10 pruned. \n",
      "[I 2024-12-21 23:17:17,173] Trial 11 finished with value: 84.91379310344827 and parameters: {'n_linear_layers': 2, 'n_units_l0': 34, 'activation': 'Sigmoid', 'n_units_l1': 378, 'optimizer': 'Adam', 'lr': 0.002432111616434018}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:17:18,656] Trial 12 pruned. \n",
      "[I 2024-12-21 23:17:46,506] Trial 13 finished with value: 86.63793103448276 and parameters: {'n_linear_layers': 1, 'n_units_l0': 244, 'activation': 'CELU', 'optimizer': 'Adam', 'lr': 0.0034719365387319346}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:18:15,424] Trial 14 finished with value: 90.94827586206897 and parameters: {'n_linear_layers': 1, 'n_units_l0': 403, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.00041650873877910056}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:18:17,019] Trial 15 pruned. \n",
      "[I 2024-12-21 23:18:44,213] Trial 16 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 1, 'n_units_l0': 585, 'activation': 'ReLU', 'optimizer': 'RMSprop', 'lr': 0.0005051148198389538}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:18:45,898] Trial 17 pruned. \n",
      "[I 2024-12-21 23:18:50,268] Trial 18 pruned. \n",
      "[I 2024-12-21 23:19:21,953] Trial 19 finished with value: 90.94827586206897 and parameters: {'n_linear_layers': 2, 'n_units_l0': 611, 'activation': 'Tanh', 'n_units_l1': 574, 'optimizer': 'RMSprop', 'lr': 0.0007184624437240875}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:19:23,503] Trial 20 pruned. \n",
      "[I 2024-12-21 23:19:54,137] Trial 21 finished with value: 89.22413793103449 and parameters: {'n_linear_layers': 2, 'n_units_l0': 648, 'activation': 'Tanh', 'n_units_l1': 585, 'optimizer': 'RMSprop', 'lr': 0.0006666733962269503}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:19:55,575] Trial 22 pruned. \n",
      "[I 2024-12-21 23:20:26,693] Trial 23 finished with value: 90.94827586206897 and parameters: {'n_linear_layers': 2, 'n_units_l0': 623, 'activation': 'Tanh', 'n_units_l1': 889, 'optimizer': 'RMSprop', 'lr': 0.0006427782704219308}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:20:54,671] Trial 24 finished with value: 89.22413793103449 and parameters: {'n_linear_layers': 2, 'n_units_l0': 477, 'activation': 'Tanh', 'n_units_l1': 179, 'optimizer': 'RMSprop', 'lr': 0.00016904728284352337}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:20:56,193] Trial 25 pruned. \n",
      "[I 2024-12-21 23:20:57,728] Trial 26 pruned. \n",
      "[I 2024-12-21 23:20:59,453] Trial 27 pruned. \n",
      "[I 2024-12-21 23:21:00,858] Trial 28 pruned. \n",
      "[I 2024-12-21 23:21:02,465] Trial 29 pruned. \n",
      "[I 2024-12-21 23:21:31,290] Trial 30 finished with value: 90.94827586206897 and parameters: {'n_linear_layers': 1, 'n_units_l0': 482, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.004403223316547328}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:22:02,836] Trial 31 finished with value: 90.08620689655173 and parameters: {'n_linear_layers': 2, 'n_units_l0': 650, 'activation': 'Tanh', 'n_units_l1': 898, 'optimizer': 'RMSprop', 'lr': 0.0006692094223994441}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:22:31,398] Trial 32 finished with value: 88.36206896551724 and parameters: {'n_linear_layers': 2, 'n_units_l0': 589, 'activation': 'Tanh', 'n_units_l1': 151, 'optimizer': 'RMSprop', 'lr': 0.0004276932628230183}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:22:42,115] Trial 33 pruned. \n",
      "[I 2024-12-21 23:22:43,516] Trial 34 pruned. \n",
      "[I 2024-12-21 23:22:45,045] Trial 35 pruned. \n",
      "[I 2024-12-21 23:22:47,719] Trial 36 pruned. \n",
      "[I 2024-12-21 23:22:49,185] Trial 37 pruned. \n",
      "[I 2024-12-21 23:22:50,694] Trial 38 pruned. \n",
      "[I 2024-12-21 23:23:18,362] Trial 39 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 1, 'n_units_l0': 812, 'activation': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.0007006525039517956}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:23:20,039] Trial 40 pruned. \n",
      "[I 2024-12-21 23:23:21,938] Trial 41 pruned. \n",
      "[I 2024-12-21 23:23:53,070] Trial 42 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 1, 'n_units_l0': 484, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.001474150448289409}. Best is trial 5 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:23:53,078] A new study created in memory with name: no-name-e6038af5-635a-4b89-8e60-809d079ef284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  43\n",
      "  Number of pruned trials:  24\n",
      "  Number of complete trials:  19\n",
      "Best trial:\n",
      "  Value:  90.94827586206897\n",
      "  Params: \n",
      "    n_linear_layers: 2\n",
      "    n_units_l0: 347\n",
      "    activation: ReLU\n",
      "    n_units_l1: 120\n",
      "    optimizer: Adam\n",
      "    lr: 0.0012373312350259724\n",
      "  Final MSE: 2218.880998726549\n",
      "Repeat:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 23:24:23,503] Trial 0 finished with value: 88.79310344827587 and parameters: {'n_linear_layers': 1, 'n_units_l0': 101, 'activation': 'LeakyReLU', 'optimizer': 'RMSprop', 'lr': 6.332712646506002e-05}. Best is trial 0 with value: 88.79310344827587.\n",
      "[I 2024-12-21 23:24:52,120] Trial 1 finished with value: 90.94827586206897 and parameters: {'n_linear_layers': 1, 'n_units_l0': 389, 'activation': 'ReLU', 'optimizer': 'Adam', 'lr': 7.223883211761309e-05}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:25:20,104] Trial 2 finished with value: 90.08620689655173 and parameters: {'n_linear_layers': 1, 'n_units_l0': 848, 'activation': 'Sigmoid', 'optimizer': 'RMSprop', 'lr': 0.0013664908343332585}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:25:49,374] Trial 3 finished with value: 88.36206896551724 and parameters: {'n_linear_layers': 2, 'n_units_l0': 159, 'activation': 'CELU', 'n_units_l1': 32, 'optimizer': 'RMSprop', 'lr': 0.00020539938662121341}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:26:13,472] Trial 4 finished with value: 81.46551724137932 and parameters: {'n_linear_layers': 2, 'n_units_l0': 591, 'activation': 'LeakyReLU', 'n_units_l1': 445, 'optimizer': 'SGD', 'lr': 0.00011801717495198642}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:26:19,018] Trial 5 pruned. \n",
      "[I 2024-12-21 23:26:20,555] Trial 6 pruned. \n",
      "[I 2024-12-21 23:26:52,530] Trial 7 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 2, 'n_units_l0': 305, 'activation': 'ReLU', 'n_units_l1': 372, 'optimizer': 'Adam', 'lr': 0.0007695378609072304}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:26:53,982] Trial 8 pruned. \n",
      "[I 2024-12-21 23:26:55,410] Trial 9 pruned. \n",
      "[I 2024-12-21 23:26:56,938] Trial 10 pruned. \n",
      "[I 2024-12-21 23:27:29,375] Trial 11 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 2, 'n_units_l0': 249, 'activation': 'ReLU', 'n_units_l1': 853, 'optimizer': 'Adam', 'lr': 0.0011216157370989948}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:27:55,152] Trial 12 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 1, 'n_units_l0': 554, 'activation': 'ReLU', 'optimizer': 'Adam', 'lr': 0.0005321072606295547}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:27:56,558] Trial 13 pruned. \n",
      "[I 2024-12-21 23:28:21,359] Trial 14 finished with value: 90.08620689655173 and parameters: {'n_linear_layers': 1, 'n_units_l0': 405, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.0038477054990607652}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:28:22,794] Trial 15 pruned. \n",
      "[I 2024-12-21 23:28:24,255] Trial 16 pruned. \n",
      "[I 2024-12-21 23:28:25,850] Trial 17 pruned. \n",
      "[I 2024-12-21 23:28:27,239] Trial 18 pruned. \n",
      "[I 2024-12-21 23:28:28,764] Trial 19 pruned. \n",
      "[I 2024-12-21 23:28:30,182] Trial 20 pruned. \n",
      "[I 2024-12-21 23:28:31,686] Trial 21 pruned. \n",
      "[I 2024-12-21 23:29:01,366] Trial 22 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 2, 'n_units_l0': 422, 'activation': 'ReLU', 'n_units_l1': 899, 'optimizer': 'Adam', 'lr': 0.0010730870804828742}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:29:02,759] Trial 23 pruned. \n",
      "[I 2024-12-21 23:29:04,194] Trial 24 pruned. \n",
      "[I 2024-12-21 23:29:05,774] Trial 25 pruned. \n",
      "[I 2024-12-21 23:29:34,777] Trial 26 finished with value: 90.08620689655173 and parameters: {'n_linear_layers': 2, 'n_units_l0': 499, 'activation': 'ReLU', 'n_units_l1': 555, 'optimizer': 'Adam', 'lr': 0.0004687825914521214}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:30:03,933] Trial 27 finished with value: 88.79310344827587 and parameters: {'n_linear_layers': 2, 'n_units_l0': 348, 'activation': 'ReLU', 'n_units_l1': 760, 'optimizer': 'Adam', 'lr': 0.0003199582556449854}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:30:05,380] Trial 28 pruned. \n",
      "[I 2024-12-21 23:30:06,818] Trial 29 pruned. \n",
      "[I 2024-12-21 23:30:08,573] Trial 30 pruned. \n",
      "[I 2024-12-21 23:30:38,007] Trial 31 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 2, 'n_units_l0': 432, 'activation': 'ReLU', 'n_units_l1': 890, 'optimizer': 'Adam', 'lr': 0.0010980358197122345}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:30:39,411] Trial 32 pruned. \n",
      "[I 2024-12-21 23:30:40,903] Trial 33 pruned. \n",
      "[I 2024-12-21 23:30:42,397] Trial 34 pruned. \n",
      "[I 2024-12-21 23:30:44,021] Trial 35 pruned. \n",
      "[I 2024-12-21 23:30:45,475] Trial 36 pruned. \n",
      "[I 2024-12-21 23:30:47,059] Trial 37 pruned. \n",
      "[I 2024-12-21 23:30:48,584] Trial 38 pruned. \n",
      "[I 2024-12-21 23:30:50,326] Trial 39 pruned. \n",
      "[I 2024-12-21 23:30:51,823] Trial 40 pruned. \n",
      "[I 2024-12-21 23:30:53,381] Trial 41 pruned. \n",
      "[I 2024-12-21 23:30:54,892] Trial 42 pruned. \n",
      "[I 2024-12-21 23:30:56,595] Trial 43 pruned. \n",
      "[I 2024-12-21 23:30:58,106] Trial 44 pruned. \n",
      "[I 2024-12-21 23:30:59,608] Trial 45 pruned. \n",
      "[I 2024-12-21 23:31:01,087] Trial 46 pruned. \n",
      "[I 2024-12-21 23:31:02,555] Trial 47 pruned. \n",
      "[I 2024-12-21 23:31:04,140] Trial 48 pruned. \n",
      "[I 2024-12-21 23:31:05,537] Trial 49 pruned. \n",
      "[I 2024-12-21 23:31:07,024] Trial 50 pruned. \n",
      "[I 2024-12-21 23:31:33,562] Trial 51 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 1, 'n_units_l0': 826, 'activation': 'Sigmoid', 'optimizer': 'RMSprop', 'lr': 0.0013391609388424747}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:31:35,039] Trial 52 pruned. \n",
      "[I 2024-12-21 23:31:36,877] Trial 53 pruned. \n",
      "[I 2024-12-21 23:31:38,577] Trial 54 pruned. \n",
      "[I 2024-12-21 23:31:40,011] Trial 55 pruned. \n",
      "[I 2024-12-21 23:32:05,162] Trial 56 finished with value: 89.22413793103449 and parameters: {'n_linear_layers': 1, 'n_units_l0': 281, 'activation': 'ReLU', 'optimizer': 'Adam', 'lr': 0.0016229466912616249}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:32:06,598] Trial 57 pruned. \n",
      "[I 2024-12-21 23:32:08,103] Trial 58 pruned. \n",
      "[I 2024-12-21 23:32:09,623] Trial 59 pruned. \n",
      "[I 2024-12-21 23:32:11,134] Trial 60 pruned. \n",
      "[I 2024-12-21 23:32:12,663] Trial 61 pruned. \n",
      "[I 2024-12-21 23:32:14,375] Trial 62 pruned. \n",
      "[I 2024-12-21 23:32:15,798] Trial 63 pruned. \n",
      "[I 2024-12-21 23:32:41,940] Trial 64 finished with value: 88.79310344827587 and parameters: {'n_linear_layers': 1, 'n_units_l0': 807, 'activation': 'Sigmoid', 'optimizer': 'RMSprop', 'lr': 0.0013869899778928751}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:32:43,405] Trial 65 pruned. \n",
      "[I 2024-12-21 23:32:44,927] Trial 66 pruned. \n",
      "[I 2024-12-21 23:32:46,453] Trial 67 pruned. \n",
      "[I 2024-12-21 23:32:47,959] Trial 68 pruned. \n",
      "[I 2024-12-21 23:32:49,566] Trial 69 pruned. \n",
      "[I 2024-12-21 23:32:51,007] Trial 70 pruned. \n",
      "[I 2024-12-21 23:33:16,925] Trial 71 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 1, 'n_units_l0': 369, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.003658163826623957}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:33:18,450] Trial 72 pruned. \n",
      "[I 2024-12-21 23:33:19,901] Trial 73 pruned. \n",
      "[I 2024-12-21 23:33:21,678] Trial 74 pruned. \n",
      "[I 2024-12-21 23:33:23,214] Trial 75 pruned. \n",
      "[I 2024-12-21 23:33:24,700] Trial 76 pruned. \n",
      "[I 2024-12-21 23:33:26,555] Trial 77 pruned. \n",
      "[I 2024-12-21 23:33:28,008] Trial 78 pruned. \n",
      "[I 2024-12-21 23:33:29,492] Trial 79 pruned. \n",
      "[I 2024-12-21 23:33:31,034] Trial 80 pruned. \n",
      "[I 2024-12-21 23:33:32,884] Trial 81 pruned. \n",
      "[I 2024-12-21 23:34:00,864] Trial 82 finished with value: 90.94827586206897 and parameters: {'n_linear_layers': 1, 'n_units_l0': 437, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.004479317310184309}. Best is trial 1 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:34:00,874] A new study created in memory with name: no-name-6a0a4435-8d07-45f8-9f85-316c00b522c1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  83\n",
      "  Number of pruned trials:  65\n",
      "  Number of complete trials:  18\n",
      "Best trial:\n",
      "  Value:  90.94827586206897\n",
      "  Params: \n",
      "    n_linear_layers: 1\n",
      "    n_units_l0: 389\n",
      "    activation: ReLU\n",
      "    optimizer: Adam\n",
      "    lr: 7.223883211761309e-05\n",
      "  Final MSE: 258.60660647575196\n",
      "Repeat:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 23:34:28,134] Trial 0 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 1, 'n_units_l0': 256, 'activation': 'Sigmoid', 'optimizer': 'RMSprop', 'lr': 0.0006219377223549593}. Best is trial 0 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:34:54,530] Trial 1 finished with value: 90.08620689655173 and parameters: {'n_linear_layers': 1, 'n_units_l0': 502, 'activation': 'ReLU', 'optimizer': 'RMSprop', 'lr': 0.00044071951767954935}. Best is trial 0 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:35:19,743] Trial 2 finished with value: 85.34482758620689 and parameters: {'n_linear_layers': 2, 'n_units_l0': 773, 'activation': 'Tanh', 'n_units_l1': 527, 'optimizer': 'SGD', 'lr': 0.0006287641942722175}. Best is trial 0 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:35:46,611] Trial 3 finished with value: 89.22413793103449 and parameters: {'n_linear_layers': 1, 'n_units_l0': 332, 'activation': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 1.5014890030339346e-05}. Best is trial 0 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:36:15,697] Trial 4 finished with value: 87.93103448275862 and parameters: {'n_linear_layers': 2, 'n_units_l0': 21, 'activation': 'LeakyReLU', 'n_units_l1': 844, 'optimizer': 'Adam', 'lr': 0.02544885208472304}. Best is trial 0 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:36:44,076] Trial 5 finished with value: 91.37931034482759 and parameters: {'n_linear_layers': 2, 'n_units_l0': 796, 'activation': 'Sigmoid', 'n_units_l1': 343, 'optimizer': 'RMSprop', 'lr': 0.0021272351775612026}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:37:09,156] Trial 6 finished with value: 90.94827586206897 and parameters: {'n_linear_layers': 2, 'n_units_l0': 541, 'activation': 'LeakyReLU', 'n_units_l1': 262, 'optimizer': 'SGD', 'lr': 0.025443222928283417}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:37:10,664] Trial 7 pruned. \n",
      "[I 2024-12-21 23:37:12,137] Trial 8 pruned. \n",
      "[I 2024-12-21 23:37:13,568] Trial 9 pruned. \n",
      "[I 2024-12-21 23:37:15,084] Trial 10 pruned. \n",
      "[I 2024-12-21 23:37:16,531] Trial 11 pruned. \n",
      "[I 2024-12-21 23:37:40,788] Trial 12 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 2, 'n_units_l0': 639, 'activation': 'LeakyReLU', 'n_units_l1': 367, 'optimizer': 'SGD', 'lr': 0.09681021742119086}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:37:42,235] Trial 13 pruned. \n",
      "[I 2024-12-21 23:37:43,765] Trial 14 pruned. \n",
      "[I 2024-12-21 23:37:45,211] Trial 15 pruned. \n",
      "[I 2024-12-21 23:37:46,613] Trial 16 pruned. \n",
      "[I 2024-12-21 23:37:48,137] Trial 17 pruned. \n",
      "[I 2024-12-21 23:37:49,654] Trial 18 pruned. \n",
      "[I 2024-12-21 23:37:51,101] Trial 19 pruned. \n",
      "[I 2024-12-21 23:37:52,615] Trial 20 pruned. \n",
      "[I 2024-12-21 23:38:18,604] Trial 21 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 1, 'n_units_l0': 225, 'activation': 'Sigmoid', 'optimizer': 'RMSprop', 'lr': 0.0017100475778384161}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:38:20,085] Trial 22 pruned. \n",
      "[I 2024-12-21 23:38:21,588] Trial 23 pruned. \n",
      "[I 2024-12-21 23:38:24,328] Trial 24 pruned. \n",
      "[I 2024-12-21 23:38:25,810] Trial 25 pruned. \n",
      "[I 2024-12-21 23:38:27,286] Trial 26 pruned. \n",
      "[I 2024-12-21 23:38:28,945] Trial 27 pruned. \n",
      "[I 2024-12-21 23:38:30,314] Trial 28 pruned. \n",
      "[I 2024-12-21 23:38:31,773] Trial 29 pruned. \n",
      "[I 2024-12-21 23:38:33,303] Trial 30 pruned. \n",
      "[I 2024-12-21 23:38:55,428] Trial 31 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 2, 'n_units_l0': 608, 'activation': 'LeakyReLU', 'n_units_l1': 345, 'optimizer': 'SGD', 'lr': 0.06741761941675777}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:38:56,942] Trial 32 pruned. \n",
      "[I 2024-12-21 23:38:58,379] Trial 33 pruned. \n",
      "[I 2024-12-21 23:38:59,953] Trial 34 pruned. \n",
      "[I 2024-12-21 23:39:01,370] Trial 35 pruned. \n",
      "[I 2024-12-21 23:39:02,803] Trial 36 pruned. \n",
      "[I 2024-12-21 23:39:04,330] Trial 37 pruned. \n",
      "[I 2024-12-21 23:39:05,931] Trial 38 pruned. \n",
      "[I 2024-12-21 23:39:07,393] Trial 39 pruned. \n",
      "[I 2024-12-21 23:39:08,906] Trial 40 pruned. \n",
      "[I 2024-12-21 23:39:10,426] Trial 41 pruned. \n",
      "[I 2024-12-21 23:39:12,481] Trial 42 pruned. \n",
      "[I 2024-12-21 23:39:13,870] Trial 43 pruned. \n",
      "[I 2024-12-21 23:39:15,303] Trial 44 pruned. \n",
      "[I 2024-12-21 23:39:16,866] Trial 45 pruned. \n",
      "[I 2024-12-21 23:39:18,332] Trial 46 pruned. \n",
      "[I 2024-12-21 23:39:19,818] Trial 47 pruned. \n",
      "[I 2024-12-21 23:39:21,359] Trial 48 pruned. \n",
      "[I 2024-12-21 23:39:22,899] Trial 49 pruned. \n",
      "[I 2024-12-21 23:39:24,372] Trial 50 pruned. \n",
      "[I 2024-12-21 23:39:50,390] Trial 51 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 1, 'n_units_l0': 508, 'activation': 'ReLU', 'optimizer': 'RMSprop', 'lr': 0.0015404969380128407}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:39:53,979] Trial 52 pruned. \n",
      "[I 2024-12-21 23:39:55,420] Trial 53 pruned. \n",
      "[I 2024-12-21 23:39:56,943] Trial 54 pruned. \n",
      "[I 2024-12-21 23:39:58,440] Trial 55 pruned. \n",
      "[I 2024-12-21 23:39:59,875] Trial 56 pruned. \n",
      "[I 2024-12-21 23:40:01,375] Trial 57 pruned. \n",
      "[I 2024-12-21 23:40:02,929] Trial 58 pruned. \n",
      "[I 2024-12-21 23:40:04,314] Trial 59 pruned. \n",
      "[I 2024-12-21 23:40:05,799] Trial 60 pruned. \n",
      "[I 2024-12-21 23:40:07,276] Trial 61 pruned. \n",
      "[I 2024-12-21 23:40:31,115] Trial 62 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 2, 'n_units_l0': 617, 'activation': 'LeakyReLU', 'n_units_l1': 380, 'optimizer': 'SGD', 'lr': 0.06555348727742946}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:40:32,779] Trial 63 pruned. \n",
      "[I 2024-12-21 23:40:59,296] Trial 64 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 2, 'n_units_l0': 696, 'activation': 'LeakyReLU', 'n_units_l1': 266, 'optimizer': 'SGD', 'lr': 0.05538761763044453}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:41:00,880] Trial 65 pruned. \n",
      "[I 2024-12-21 23:41:02,285] Trial 66 pruned. \n",
      "[I 2024-12-21 23:41:03,795] Trial 67 pruned. \n",
      "[I 2024-12-21 23:41:32,282] Trial 68 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 2, 'n_units_l0': 535, 'activation': 'LeakyReLU', 'n_units_l1': 516, 'optimizer': 'RMSprop', 'lr': 0.0005068948659706257}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:41:33,666] Trial 69 pruned. \n",
      "[I 2024-12-21 23:41:35,251] Trial 70 pruned. \n",
      "[I 2024-12-21 23:41:36,933] Trial 71 pruned. \n",
      "[I 2024-12-21 23:41:38,410] Trial 72 pruned. \n",
      "[I 2024-12-21 23:41:39,901] Trial 73 pruned. \n",
      "[I 2024-12-21 23:41:41,346] Trial 74 pruned. \n",
      "[I 2024-12-21 23:41:42,907] Trial 75 pruned. \n",
      "[I 2024-12-21 23:41:44,691] Trial 76 pruned. \n",
      "[I 2024-12-21 23:41:46,189] Trial 77 pruned. \n",
      "[I 2024-12-21 23:41:47,656] Trial 78 pruned. \n",
      "[I 2024-12-21 23:41:49,150] Trial 79 pruned. \n",
      "[I 2024-12-21 23:41:50,648] Trial 80 pruned. \n",
      "[I 2024-12-21 23:41:52,132] Trial 81 pruned. \n",
      "[I 2024-12-21 23:41:53,650] Trial 82 pruned. \n",
      "[I 2024-12-21 23:41:55,069] Trial 83 pruned. \n",
      "[I 2024-12-21 23:41:56,580] Trial 84 pruned. \n",
      "[I 2024-12-21 23:41:58,102] Trial 85 pruned. \n",
      "[I 2024-12-21 23:41:59,555] Trial 86 pruned. \n",
      "[I 2024-12-21 23:42:01,152] Trial 87 pruned. \n",
      "[I 2024-12-21 23:42:02,593] Trial 88 pruned. \n",
      "[I 2024-12-21 23:42:04,261] Trial 89 pruned. \n",
      "[I 2024-12-21 23:42:05,715] Trial 90 pruned. \n",
      "[I 2024-12-21 23:42:07,167] Trial 91 pruned. \n",
      "[I 2024-12-21 23:42:31,828] Trial 92 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 2, 'n_units_l0': 678, 'activation': 'LeakyReLU', 'n_units_l1': 329, 'optimizer': 'SGD', 'lr': 0.0600135371181529}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:42:55,877] Trial 93 finished with value: 89.22413793103449 and parameters: {'n_linear_layers': 2, 'n_units_l0': 601, 'activation': 'LeakyReLU', 'n_units_l1': 330, 'optimizer': 'SGD', 'lr': 0.09547737220848929}. Best is trial 5 with value: 91.37931034482759.\n",
      "[I 2024-12-21 23:42:57,318] Trial 94 pruned. \n",
      "[I 2024-12-21 23:42:58,873] Trial 95 pruned. \n",
      "[I 2024-12-21 23:43:00,261] Trial 96 pruned. \n",
      "[I 2024-12-21 23:43:01,904] Trial 97 pruned. \n",
      "[I 2024-12-21 23:43:03,228] Trial 98 pruned. \n",
      "[I 2024-12-21 23:43:04,949] Trial 99 pruned. \n",
      "[I 2024-12-21 23:43:04,960] A new study created in memory with name: no-name-8be6aa74-6e02-4e0e-a9b8-1dc657ebb259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  84\n",
      "  Number of complete trials:  16\n",
      "Best trial:\n",
      "  Value:  91.37931034482759\n",
      "  Params: \n",
      "    n_linear_layers: 2\n",
      "    n_units_l0: 796\n",
      "    activation: Sigmoid\n",
      "    n_units_l1: 343\n",
      "    optimizer: RMSprop\n",
      "    lr: 0.0021272351775612026\n",
      "  Final MSE: 1868.166895767738\n",
      "Repeat:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-21 23:43:30,554] Trial 0 finished with value: 89.22413793103449 and parameters: {'n_linear_layers': 1, 'n_units_l0': 173, 'activation': 'CELU', 'optimizer': 'Adam', 'lr': 7.388419886122607e-05}. Best is trial 0 with value: 89.22413793103449.\n",
      "[I 2024-12-21 23:43:58,570] Trial 1 finished with value: 88.79310344827587 and parameters: {'n_linear_layers': 2, 'n_units_l0': 89, 'activation': 'Tanh', 'n_units_l1': 648, 'optimizer': 'Adam', 'lr': 7.112105738485635e-05}. Best is trial 0 with value: 89.22413793103449.\n",
      "[I 2024-12-21 23:44:21,188] Trial 2 finished with value: 75.86206896551724 and parameters: {'n_linear_layers': 1, 'n_units_l0': 733, 'activation': 'Sigmoid', 'optimizer': 'SGD', 'lr': 0.00020039563003033915}. Best is trial 0 with value: 89.22413793103449.\n",
      "[I 2024-12-21 23:44:48,387] Trial 3 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 1, 'n_units_l0': 686, 'activation': 'Sigmoid', 'optimizer': 'RMSprop', 'lr': 0.0013900692309662716}. Best is trial 3 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:45:13,656] Trial 4 finished with value: 88.36206896551724 and parameters: {'n_linear_layers': 2, 'n_units_l0': 203, 'activation': 'CELU', 'n_units_l1': 140, 'optimizer': 'SGD', 'lr': 0.08413918720564269}. Best is trial 3 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:45:15,175] Trial 5 pruned. \n",
      "[I 2024-12-21 23:45:42,655] Trial 6 finished with value: 88.79310344827587 and parameters: {'n_linear_layers': 2, 'n_units_l0': 719, 'activation': 'CELU', 'n_units_l1': 486, 'optimizer': 'Adam', 'lr': 0.0001784161447481834}. Best is trial 3 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:46:09,028] Trial 7 finished with value: 88.79310344827587 and parameters: {'n_linear_layers': 2, 'n_units_l0': 72, 'activation': 'ReLU', 'n_units_l1': 384, 'optimizer': 'RMSprop', 'lr': 0.0018754985473163437}. Best is trial 3 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:46:10,441] Trial 8 pruned. \n",
      "[I 2024-12-21 23:46:12,117] Trial 9 pruned. \n",
      "[I 2024-12-21 23:46:13,469] Trial 10 pruned. \n",
      "[I 2024-12-21 23:46:41,277] Trial 11 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 1, 'n_units_l0': 488, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.0009654956414185582}. Best is trial 3 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:47:08,838] Trial 12 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 1, 'n_units_l0': 516, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.0017013514598691148}. Best is trial 3 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:47:10,343] Trial 13 pruned. \n",
      "[I 2024-12-21 23:47:11,997] Trial 14 pruned. \n",
      "[I 2024-12-21 23:47:37,495] Trial 15 finished with value: 89.22413793103449 and parameters: {'n_linear_layers': 1, 'n_units_l0': 584, 'activation': 'LeakyReLU', 'optimizer': 'RMSprop', 'lr': 0.0006659066312106049}. Best is trial 3 with value: 90.51724137931035.\n",
      "[I 2024-12-21 23:47:38,957] Trial 16 pruned. \n",
      "[I 2024-12-21 23:47:40,814] Trial 17 pruned. \n",
      "[I 2024-12-21 23:47:42,229] Trial 18 pruned. \n",
      "[I 2024-12-21 23:47:43,783] Trial 19 pruned. \n",
      "[I 2024-12-21 23:47:45,408] Trial 20 pruned. \n",
      "[I 2024-12-21 23:48:14,186] Trial 21 finished with value: 90.94827586206897 and parameters: {'n_linear_layers': 1, 'n_units_l0': 507, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.001916978918938718}. Best is trial 21 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:48:16,024] Trial 22 pruned. \n",
      "[I 2024-12-21 23:48:17,615] Trial 23 pruned. \n",
      "[I 2024-12-21 23:48:19,127] Trial 24 pruned. \n",
      "[I 2024-12-21 23:48:20,636] Trial 25 pruned. \n",
      "[I 2024-12-21 23:48:22,135] Trial 26 pruned. \n",
      "[I 2024-12-21 23:48:23,574] Trial 27 pruned. \n",
      "[I 2024-12-21 23:48:25,041] Trial 28 pruned. \n",
      "[I 2024-12-21 23:48:26,631] Trial 29 pruned. \n",
      "[I 2024-12-21 23:48:55,512] Trial 30 finished with value: 90.94827586206897 and parameters: {'n_linear_layers': 1, 'n_units_l0': 534, 'activation': 'Tanh', 'optimizer': 'Adam', 'lr': 0.0003780929097137288}. Best is trial 21 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:49:24,161] Trial 31 finished with value: 89.22413793103449 and parameters: {'n_linear_layers': 1, 'n_units_l0': 535, 'activation': 'Tanh', 'optimizer': 'Adam', 'lr': 0.00045509918597513366}. Best is trial 21 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:49:51,194] Trial 32 finished with value: 90.08620689655173 and parameters: {'n_linear_layers': 1, 'n_units_l0': 628, 'activation': 'Tanh', 'optimizer': 'Adam', 'lr': 0.0009975139568782832}. Best is trial 21 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:49:52,660] Trial 33 pruned. \n",
      "[I 2024-12-21 23:49:54,194] Trial 34 pruned. \n",
      "[I 2024-12-21 23:49:55,655] Trial 35 pruned. \n",
      "[I 2024-12-21 23:49:57,108] Trial 36 pruned. \n",
      "[I 2024-12-21 23:49:58,610] Trial 37 pruned. \n",
      "[I 2024-12-21 23:50:00,078] Trial 38 pruned. \n",
      "[I 2024-12-21 23:50:01,551] Trial 39 pruned. \n",
      "[I 2024-12-21 23:50:03,080] Trial 40 pruned. \n",
      "[I 2024-12-21 23:50:30,193] Trial 41 finished with value: 90.08620689655173 and parameters: {'n_linear_layers': 1, 'n_units_l0': 509, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.0016654357625555084}. Best is trial 21 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:50:31,673] Trial 42 pruned. \n",
      "[I 2024-12-21 23:50:33,293] Trial 43 pruned. \n",
      "[I 2024-12-21 23:50:34,917] Trial 44 pruned. \n",
      "[I 2024-12-21 23:50:36,541] Trial 45 pruned. \n",
      "[I 2024-12-21 23:50:38,087] Trial 46 pruned. \n",
      "[I 2024-12-21 23:50:39,493] Trial 47 pruned. \n",
      "[I 2024-12-21 23:50:41,034] Trial 48 pruned. \n",
      "[I 2024-12-21 23:50:42,740] Trial 49 pruned. \n",
      "[I 2024-12-21 23:50:44,441] Trial 50 pruned. \n",
      "[I 2024-12-21 23:50:45,958] Trial 51 pruned. \n",
      "[I 2024-12-21 23:50:47,527] Trial 52 pruned. \n",
      "[I 2024-12-21 23:50:50,722] Trial 53 pruned. \n",
      "[I 2024-12-21 23:50:52,363] Trial 54 pruned. \n",
      "[I 2024-12-21 23:50:53,940] Trial 55 pruned. \n",
      "[I 2024-12-21 23:50:55,347] Trial 56 pruned. \n",
      "[I 2024-12-21 23:51:21,989] Trial 57 finished with value: 89.22413793103449 and parameters: {'n_linear_layers': 1, 'n_units_l0': 408, 'activation': 'Tanh', 'optimizer': 'Adam', 'lr': 0.0033164335472386512}. Best is trial 21 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:51:23,539] Trial 58 pruned. \n",
      "[I 2024-12-21 23:51:25,199] Trial 59 pruned. \n",
      "[I 2024-12-21 23:51:53,081] Trial 60 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 1, 'n_units_l0': 612, 'activation': 'LeakyReLU', 'optimizer': 'Adam', 'lr': 0.0011915718074637077}. Best is trial 21 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:52:22,067] Trial 61 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 1, 'n_units_l0': 526, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.001637309468653101}. Best is trial 21 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:52:23,729] Trial 62 pruned. \n",
      "[I 2024-12-21 23:52:25,299] Trial 63 pruned. \n",
      "[I 2024-12-21 23:52:53,862] Trial 64 finished with value: 90.51724137931035 and parameters: {'n_linear_layers': 1, 'n_units_l0': 557, 'activation': 'Sigmoid', 'optimizer': 'Adam', 'lr': 0.0014578525152504054}. Best is trial 21 with value: 90.94827586206897.\n",
      "[I 2024-12-21 23:52:55,496] Trial 65 pruned. \n",
      "[I 2024-12-21 23:53:20,447] Trial 66 finished with value: 89.65517241379311 and parameters: {'n_linear_layers': 1, 'n_units_l0': 376, 'activation': 'Sigmoid', 'optimizer': 'RMSprop', 'lr': 0.0014311889438117455}. Best is trial 21 with value: 90.94827586206897.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  67\n",
      "  Number of pruned trials:  47\n",
      "  Number of complete trials:  20\n",
      "Best trial:\n",
      "  Value:  90.94827586206897\n",
      "  Params: \n",
      "    n_linear_layers: 1\n",
      "    n_units_l0: 507\n",
      "    activation: Sigmoid\n",
      "    optimizer: Adam\n",
      "    lr: 0.001916978918938718\n",
      "  Final MSE: 2116.407550302045\n",
      "-----------------\n",
      "\n",
      "Repeat 1:\n",
      "Study statistics: \n",
      "  Number of finished trials: 43\n",
      "  Number of pruned trials: 24\n",
      "  Number of complete trials: 19\n",
      "Best trial:\n",
      "  Value (accuracy): 90.94827586206897\n",
      "  Params: \n",
      "    n_linear_layers: 2\n",
      "    n_units_l0: 347\n",
      "    activation: ReLU\n",
      "    n_units_l1: 120\n",
      "    optimizer: Adam\n",
      "    lr: 0.0012373312350259724\n",
      "  Final MSE: 2218.880998726549\n",
      "\n",
      "Repeat 2:\n",
      "Study statistics: \n",
      "  Number of finished trials: 83\n",
      "  Number of pruned trials: 65\n",
      "  Number of complete trials: 18\n",
      "Best trial:\n",
      "  Value (accuracy): 90.94827586206897\n",
      "  Params: \n",
      "    n_linear_layers: 1\n",
      "    n_units_l0: 389\n",
      "    activation: ReLU\n",
      "    optimizer: Adam\n",
      "    lr: 7.223883211761309e-05\n",
      "  Final MSE: 258.60660647575196\n",
      "\n",
      "Repeat 3:\n",
      "Study statistics: \n",
      "  Number of finished trials: 100\n",
      "  Number of pruned trials: 84\n",
      "  Number of complete trials: 16\n",
      "Best trial:\n",
      "  Value (accuracy): 91.37931034482759\n",
      "  Params: \n",
      "    n_linear_layers: 2\n",
      "    n_units_l0: 796\n",
      "    activation: Sigmoid\n",
      "    n_units_l1: 343\n",
      "    optimizer: RMSprop\n",
      "    lr: 0.0021272351775612026\n",
      "  Final MSE: 1868.166895767738\n",
      "\n",
      "Repeat 4:\n",
      "Study statistics: \n",
      "  Number of finished trials: 67\n",
      "  Number of pruned trials: 47\n",
      "  Number of complete trials: 20\n",
      "Best trial:\n",
      "  Value (accuracy): 90.94827586206897\n",
      "  Params: \n",
      "    n_linear_layers: 1\n",
      "    n_units_l0: 507\n",
      "    activation: Sigmoid\n",
      "    optimizer: Adam\n",
      "    lr: 0.001916978918938718\n",
      "  Final MSE: 2116.407550302045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCHSIZE = 16\n",
    "CLASSES = 3\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 400\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 20\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_linear_layers\", 1, 2)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 3*69 #heart rate, speed and altitude data\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 900)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        activation_fn = trial.suggest_categorical(\"activation\", [\"ReLU\", \"Tanh\", \"CELU\", \"Sigmoid\", \"LeakyReLU\"])\n",
    "        if activation_fn == \"ReLU\":\n",
    "            layers.append(nn.ReLU())\n",
    "        elif activation_fn == \"Tanh\":\n",
    "            layers.append(nn.Tanh())\n",
    "        elif activation_fn == \"CELU\":\n",
    "            layers.append(nn.CELU())\n",
    "        elif activation_fn == \"Sigmoid\":\n",
    "            layers.append(nn.Sigmoid())\n",
    "        elif activation_fn == \"LeakyReLU\":\n",
    "            layers.append(nn.LeakyReLU())\n",
    "        #p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        #layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    #layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def get_mnist():\n",
    "\n",
    "    # Load training data\n",
    "    name='./Exercise_Train_data.xlsx'\n",
    "\n",
    "    df = pd.read_excel(name,sheet_name='Sheet1') #load data in dataframe\n",
    "    df.drop([0],axis=0, inplace=True) #remove first row\n",
    "\n",
    "    y=df[\"Column208\"]\n",
    "    X1 = df.drop(\"Column208\", axis=1)\n",
    "\n",
    "    #We have to trasform the input and output arrays to 32-bit torch tensors\n",
    "    inputx = torch.tensor(X1.values).float()   #time series vectors\n",
    "    outputy = torch.tensor(y.values).float() #contains the classification data 0,1,2\n",
    "    train_data = torch.utils.data.TensorDataset(inputx, outputy)  # Let us encapsulate the data for\n",
    "                                                            # easier splitting and shuffling for training\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=BATCHSIZE, shuffle=True)\n",
    "                                                            #let us take 5 rows at once, shufflin allowed\n",
    "    \n",
    "    # Load test data\n",
    "    name='./Exercise_Test_data.xlsx'\n",
    "\n",
    "    df_test = pd.read_excel(name,sheet_name='Sheet1') #load data in dataframe\n",
    "    df_test.drop([0],axis=0, inplace=True) #remove first row\n",
    "\n",
    "    yx=df_test[\"Column208\"]\n",
    "    X1_test = df_test.drop(\"Column208\", axis=1)\n",
    "    y_test=yx.to_numpy()\n",
    "    y_test=y_test.astype(int)\n",
    "\n",
    "    tensori=torch.tensor(X1_test.values).float()\n",
    "    input_tensor=tensori.to(DEVICE)\n",
    "\n",
    "    #We have to trasform the input and output arrays to 32-bit torch tensors\n",
    "    inputx_test = torch.tensor(X1_test.values).float()   #time series vectors\n",
    "    outputy_test = torch.tensor(y_test).float() #contains the classification data 0,1,2\n",
    "    test_data = torch.utils.data.TensorDataset(inputx_test, outputy_test)  # Let us encapsulate the data for\n",
    "                                                            # easier splitting and shuffling for training\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=BATCHSIZE, shuffle=True)\n",
    "                                                            #let us take 5 rows at once, shufflin allowed\n",
    "    \n",
    "    return train_loader, test_loader, input_tensor, y_test #, valid_loader\n",
    "\n",
    "def validate(model, input_tensor, y_test):\n",
    "    test_values=model(input_tensor)\n",
    "    test_values=test_values.detach().cpu().numpy()\n",
    "    correct=0 \n",
    "    total=len(test_values) \n",
    "    total_mse = 0.0\n",
    "    for i in range(0,len(test_values)):\n",
    "        predicted = np.argmax(test_values[i])\n",
    "        #print(y_test[i], predicted, test_values[i])\n",
    "        correct += (predicted == y_test[i]).item()\n",
    "        # One-hot encode the labels for MSE calculation\n",
    "        label_one_hot = F.one_hot(torch.tensor(y_test[i]), num_classes=3).float()\n",
    "\n",
    "        # Calculate MSE for the current example\n",
    "        mse = F.mse_loss(torch.tensor(test_values[i]), label_one_hot, reduction=\"sum\")\n",
    "        total_mse += mse.item()\n",
    "\n",
    "\n",
    "    return total_mse / total, correct / total * 100\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "    #criterion=nn.MSELoss(reduction='sum')\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, test_loader, input_tensor, y_test = get_mnist() #, valid_loader\n",
    "\n",
    "    #scheduler reduces learning rate in places where are no significant gradient sloes in error surface\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,factor=0.9, patience=10)\n",
    "\n",
    "    #let us train the network\n",
    "    for epoch in range(EPOCHS):\n",
    "        #logs = {}\n",
    "        train_loss = 0.0\n",
    "        # supress Learning Rate after the first epoch\n",
    "        if epoch>0:\n",
    "            scheduler.step(loss)\n",
    "        #go the data trough by the baches\n",
    "        for (xd,yd) in train_loader:\n",
    "            yd = yd.type(torch.LongTensor) #for classification problems\n",
    "\n",
    "            #load the data to the device one batch at a time (input+output)       \n",
    "            xd = xd.to(DEVICE)\n",
    "            yd = yd.to(DEVICE)\n",
    "            \n",
    "            #Get predictions from the input values (batch at a time)\n",
    "            outputti = model(xd)\n",
    "            #zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Calculate Loss:  \n",
    "            loss = criterion(outputti, yd)\n",
    "            # Fed the error backwards to the network (learning from mistakes!)\n",
    "            loss.backward()\n",
    "            # Updating parameters\n",
    "            optimizer.step()\n",
    "            # Collect error for the user\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Print Learning Rate and temoral epoch error = loss \n",
    "        #if epoch % 100 == 0:\n",
    "        #    print(\"Epoch:\",epoch, \"\\tLR:\",optimizer.param_groups[0]['lr'],\"\\tTraining Loss: \", (train_loss / len(train_loader)))   \n",
    "\n",
    "\n",
    "        # calculate the accuracy of the model\n",
    "        total_mse, accuracy = validate(model, input_tensor, y_test)\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        trial.set_user_attr(\"final_mse\", total_mse)\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_repeat = 4\n",
    "    run_stats = []\n",
    "    for i in range(num_repeat):\n",
    "        current_run = {\"repeat\": i+1}\n",
    "        print(\"Repeat: \", i)\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "        pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "        complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "        print(\"Study statistics: \")\n",
    "        print(\"  Number of finished trials: \", len(study.trials))\n",
    "        print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "        print(\"  Number of complete trials: \", len(complete_trials))\n",
    "        current_run[\"num_trials\"] = len(study.trials)\n",
    "        current_run[\"num_pruned_trials\"] = len(pruned_trials)\n",
    "        current_run[\"num_complete_trials\"] = len(complete_trials)\n",
    "        print(\"Best trial:\")\n",
    "        trial = study.best_trial\n",
    "        current_run[\"best_trial\"] = trial\n",
    "        run_stats.append(current_run)\n",
    "        print(\"  Value: \", trial.value)\n",
    "\n",
    "        print(\"  Params: \")\n",
    "        for key, value in trial.params.items():\n",
    "            print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "        if \"final_mse\" in trial.user_attrs:\n",
    "            print(f\"  Final MSE: {trial.user_attrs['final_mse']}\")\n",
    "\n",
    "    print(\"-----------------\")\n",
    "    print()\n",
    "    for i, params in enumerate(run_stats):\n",
    "        print(f\"Repeat {i+1}:\")\n",
    "        print(\"Study statistics: \")\n",
    "        print(\"  Number of finished trials:\", str(params['num_trials']))\n",
    "        print(\"  Number of pruned trials:\", str(params['num_pruned_trials']))\n",
    "        print(\"  Number of complete trials:\", str(params['num_complete_trials']))\n",
    "        \n",
    "        print(\"Best trial:\")\n",
    "        print(\"  Value (accuracy):\", params['best_trial'].value)\n",
    "        print(\"  Params: \")\n",
    "        for key, value in params[\"best_trial\"].params.items():\n",
    "            print(f\"    {key}: {value}\")\n",
    "\n",
    "        if \"final_mse\" in params[\"best_trial\"].user_attrs:\n",
    "            print(f\"  Final MSE: {params['best_trial'].user_attrs['final_mse']}\")\n",
    "        \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original model results, obtained by running train_test.py :\n",
    "\n",
    "- Correct: 90.51724137931035 %\n",
    "- MSE: 8006.621066488069"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test is run for the Exercise_test_data and trained with Exercise_Train_data (same as in Parctical example code folder).\n",
    "\n",
    "Here is results of 4 different runs on trials. For 3/4 runs, the timeout (10min) stopped the run. The results for each run is better than for the original model (90.5%). The Accuracy and MSE is computed in the same way for the original and the test set. \n",
    "\n",
    "Results indicate best accuracy for the most complex model with 4 layers (86, 329, 377, 665 units). However, the MSE values for more complex models is high, which indicate that results for models with simpler architecture are more reliable. High MSE value may suggest overfitting. Based on these result, the best arhitecture would be from Run 2 or Run 4. Thus, test should be run next with layer variability set to 1-2, this would also increase the Number of Finished Trials since more computing is required for deeper architectures. Also test could be done using MSE report to trial, which would increase focus on MSE (if we want to minimize it). \n",
    "\n",
    "The dropout and logsoftmax layers are commented out but could be used to optimize model even further. This test only includes the architecture that is shown in the example code and optimization process only does search for number of layers, sizes, activation functions, optimizer and learning rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Metric                      | Run 1                                       | Run 2                                      | Run 3                                      | Run 4                                      |\n",
    "|-----------------------------|-----------------------------------------------|----------------------------------------------|----------------------------------------------|----------------------------------------------|\n",
    "| **Number of Finished Trials** | 55                                            | 100                                          | 63                                           | 73                                           |\n",
    "| **Number of Pruned Trials**   | 36                                            | 88                                           | 45                                           | 55                                           |\n",
    "| **Number of Complete Trials** | 19                                            | 12                                           | 18                                           | 18                                           |\n",
    "| **Best Accuracy (Value)**     | **92.24%**                                        | 91.38%                                       | 91.38%                                       | 91.81%                                       |\n",
    "| **Model Structure**           | 4 layers (86, 329, 377, 665 units)            | 1 layer (432 units)                          | 4 layers (554, 615, 530, 124 units)          | 2 layers (683, 104 units)                   |\n",
    "| **Activation Function**       | LeakyReLU                                     | Tanh                                         | LeakyReLU                                    | LeakyReLU                                    |\n",
    "| **Optimizer**                 | Adam                                          | Adam                                         | RMSprop                                      | SGD                                          |\n",
    "| **Learning Rate**             | 0.001604                                      | 0.00199                                      | 0.000376                                     | 0.02833                                      |\n",
    "| **Final MSE**                 | 4165.37                                       | **361.75**                                       | 5985.22                                      | 406.46                                       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second test was made based on previous results. Now using less layers, now 1-2 layers can be selected and max layer size was increased from 700 -> 900.\n",
    "Results are in table below\n",
    "\n",
    "\n",
    "| Metric                      | Run 1                                    | Run 2                                    | Run 3                                    | Run 4                                    |\n",
    "|-----------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|---------------------------------------------|\n",
    "| **Number of Finished Trials** | 43                                          | 83                                          | 100                                         | 67                                          |\n",
    "| **Number of Pruned Trials**   | 24                                          | 65                                          | 84                                          | 47                                          |\n",
    "| **Number of Complete Trials** | 19                                          | 18                                          | 16                                          | 20                                          |\n",
    "| **Best Accuracy (Value)**     | 90.95%                                      | 90.95%                                      | **91.38%**                                  | 90.95%                                      |\n",
    "| **Model Structure**           | 2 layers (347, 120 units)                  | 1 layer (389 units)                        | 2 layers (796, 343 units)                  | 1 layer (507 units)                        |\n",
    "| **Activation Function**       | ReLU                                       | ReLU                                       | Sigmoid                                    | Sigmoid                                    |\n",
    "| **Optimizer**                 | Adam                                       | Adam                                       | RMSprop                                    | Adam                                       |\n",
    "| **Learning Rate**             | 0.001237                                   | 0.0000722                                  | 0.002127                                   | 0.001916                                   |\n",
    "| **Final MSE**                 | 2218.88                                    | **258.61**                                 | 1868.17                                    | 2116.41                                    |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results show best accuracy trend for 90.95 %, which was baseline for 3 runs. Run 3 had best accuracy 91.38 % using 2 layers and Sigmoid activation function. However, the lowest MSE was for Run 2, which had 1 layer. The same trend continues as more complex architecture leads to increased MSE. One more thing to consider is that activation functions are completely different when comparing to first results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
